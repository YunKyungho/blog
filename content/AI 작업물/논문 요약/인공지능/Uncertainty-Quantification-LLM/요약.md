---
title: "A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions"
arxiv: "2412.05063"
date: 2024-12-07
tags: [LLM, 불확실성정량화, 신뢰성, 서베이]
---

## 한줄 요약
[[대규모 언어 모델|LLM]]의 신뢰성을 평가하기 위한 [[불확실성 정량화]] 방법론을 체계적으로 분류하고, 강점과 약점, 미래 연구 방향을 제시한 서베이 논문이다.

## 핵심 내용
LLM이 놀라운 성능을 보여주지만, 그 답변의 신뢰도를 판단하는 것은 여전히 어려운 과제다. 불확실성 정량화(UQ)는 모델의 예측에 대한 확신 정도를 수치화하여 이 문제를 해결하고자 한다.

### 불확실성 유형
- **인식적(Epistemic)**: 학습 데이터 부족으로 인한 불확실성
- **우연적(Aleatoric)**: 입력 자체의 본질적 모호함

### 주요 방법론
1. **확률 기반**: 토큰 확률 분포 활용
2. **샘플링 기반**: 여러 응답 생성 후 일관성 평가
3. **앙상블 기반**: 다수의 모델 출력 비교
4. **캘리브레이션**: 확률 출력의 신뢰도 조정

### 응용 분야
- 의료: 불확실한 진단 시 전문의 의뢰
- 법률: 확실한 답변만 제공
- 자율주행: 불확실할 때 보수적 행동
- 환각(Hallucination) 탐지

## 주요 개념
- [[대규모 언어 모델]]: GPT, Claude 등의 대규모 신경망 언어 모델
- [[불확실성 정량화]]: 모델 예측의 확신 정도를 수치화하는 기술
- [[딥러닝]]: 심층 신경망을 사용한 기계학습

## 입문자를 위한 학습 포인트
1. **신뢰도의 중요성**: 모델이 "모른다"고 말할 수 있는 능력의 가치
2. **환각 문제**: LLM이 자신 있게 거짓을 말하는 현상
3. **고위험 도메인**: 의료, 법률 등에서 UQ가 필수적인 이유
4. **캘리브레이션**: 모델의 확신과 실제 정확도를 일치시키는 작업
