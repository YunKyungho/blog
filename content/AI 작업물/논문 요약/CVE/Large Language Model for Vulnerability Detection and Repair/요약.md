---
title: "Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead"
arxiv: "2404.02525"
date: 2024-04-03
tags: [CVE, 보안, 서베이, LLM, 취약점탐지, 취약점수정]
---

## 한줄 요약

LLM을 활용한 취약점 탐지와 수정 연구 58편을 체계적으로 분석하고, LLM 적응 기법을 분류하며 향후 연구 로드맵을 제시한 문헌 리뷰이다.

## 핵심 내용

### 연구 범위
- 주요 SE, AI, 보안 학회 및 저널의 43편 + 프리프린트 15편 = 총 58편 분석
- 25개 학술지/학회에서 발표된 연구 포함

### 핵심 연구 질문
1. **RQ1**: 어떤 LLM이 취약점 연구에 사용되는가?
   - CodeBERT, GraphCodeBERT, CodeT5, GPT 계열 등
2. **RQ2**: 취약점 탐지를 위한 LLM 적응 기법은?
   - [[파인튜닝]], 프롬프트 튜닝, 인컨텍스트 학습
3. **RQ3**: 취약점 수정을 위한 LLM 적응 기법은?
   - 시퀀스-투-시퀀스 생성, 패치 생성, 코드 변환

### LLM 적응 기법 분류

| 분류 | 탐지 | 수정 |
|------|------|------|
| 파인튜닝 | ✅ | ✅ |
| 프롬프트 엔지니어링 | ✅ | ✅ |
| 제로샷/퓨샷 | ✅ | ✅ |
| 강화학습 | - | ✅ |

### 한계점 및 로드맵
- 데이터셋 품질 및 다양성 부족
- 실세계 적용 검증 미흡
- 해석 가능성(Explainability) 연구 필요

## 주요 개념

- [[대규모 언어 모델]]: 취약점 탐지/수정의 핵심 도구
- [[파인튜닝]]: LLM을 보안 태스크에 맞게 조정하는 핵심 기법
- [[코드 임베딩]]: GraphCodeBERT 등이 활용하는 코드 표현
- [[CVE]]: 학습 및 평가에 사용되는 취약점 데이터
- [[정적 분석]]: LLM과 결합되는 전통적 분석 방법

## 입문자를 위한 학습 포인트

1. **탐지 vs 수정의 차이**: 취약점을 찾는 것과 고치는 것은 다른 문제임을 이해
2. **LLM 적응 기법 스펙트럼**: 파인튜닝부터 제로샷까지 다양한 접근법 비교
3. **데이터셋의 중요성**: 모델 성능은 학습 데이터 품질에 크게 의존
4. **연구 트렌드**: 2024년 기준 가장 활발한 연구 분야와 향후 기회 파악
