---
title: "비전-언어 모델"
tags: [딥러닝, 멀티모달, 컴퓨터비전]
---

## 정의
비전-언어 모델(Vision-Language Model, VLM)은 이미지/영상과 텍스트를 동시에 이해하고 처리할 수 있는 멀티모달 AI 모델이다.

## 주요 모델
- **CLIP** (OpenAI): 이미지-텍스트 대조 학습
- **BLIP/BLIP-2**: 이미지 캡셔닝 및 VQA
- **LLaVA**: 비전 인스트럭션 튜닝
- **GPT-4V**: 멀티모달 [[대규모 언어 모델]]
- **Gemini**: 구글의 네이티브 멀티모달 모델

## 핵심 기술
- **교차 어텐션 (Cross-Attention)**: 시각과 언어 특징 간 상호작용
- **대조 학습**: 이미지-텍스트 쌍의 유사도 학습
- **비전 인코더**: [[합성곱 신경망]] 또는 Vision [[트랜스포머]]
- **프로젝션 레이어**: 모달리티 간 특징 정렬

## 응용 분야
- 이미지 캡셔닝
- 시각적 질의응답 (VQA)
- 이미지 검색
- 가짜 뉴스 탐지
- 의료 이미지 분석

## 가짜 뉴스 탐지에서의 역할
텍스트만으로는 파악하기 어려운 [[딥페이크]] 이미지나 조작된 시각 자료를 함께 분석하여 가짜 뉴스를 더 정확하게 탐지할 수 있다.
